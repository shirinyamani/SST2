{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751835a3-2002-462a-b812-f34022afdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from InstructorEmbedding import INSTRUCTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd9c99-ba59-46d8-964e-2d44f06f41f5",
   "metadata": {},
   "source": [
    "## EDA of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30929b75-bcdc-4e70-a3db-e6c10f3925af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2 = datasets.load_dataset('sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d96240-37e6-4e3e-92b0-de4b2fa39480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['idx', 'sentence', 'label'],\n",
       " 'validation': ['idx', 'sentence', 'label'],\n",
       " 'test': ['idx', 'sentence', 'label']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(sst2)\n",
    "sst2.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540b8eaa-28ed-4c85-8c98-8fd94f9dc674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 67349, 'validation': 872, 'test': 1821}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b9d47eb-c810-423c-a12a-090d3858fb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hide new secretions from the parental units ',\n",
       " 'contains no wit , only labored gags ',\n",
       " 'that loves its characters and communicates something rather beautiful about human nature ',\n",
       " 'remains utterly satisfied to remain the same throughout ',\n",
       " 'on the worst revenge-of-the-nerds clichés the filmmakers could dredge up ',\n",
       " \"that 's far too tragic to merit such superficial treatment \",\n",
       " 'demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . ',\n",
       " 'of saucy ',\n",
       " \"a depressed fifteen-year-old 's suicidal poetry \",\n",
       " \"are more deeply thought through than in most ` right-thinking ' films \",\n",
       " 'goes to absurd lengths ',\n",
       " \"for those moviegoers who complain that ` they do n't make movies like they used to anymore \",\n",
       " \"the part where nothing 's happening , \",\n",
       " 'saw how bad this movie was ',\n",
       " 'lend some dignity to a dumb story ',\n",
       " 'the greatest musicians ',\n",
       " 'cold movie ',\n",
       " 'with his usual intelligence and subtlety ',\n",
       " 'redundant concept ',\n",
       " \"swimming is above all about a young woman 's face , and by casting an actress whose face projects that woman 's doubts and yearnings , it succeeds . \",\n",
       " 'equals the original and in some ways even betters it ',\n",
       " 'if anything , see it for karen black , who camps up a storm as a fringe feminist conspiracy theorist named dirty dick . ',\n",
       " 'a smile on your face ',\n",
       " 'comes from the brave , uninhibited performances ',\n",
       " 'excruciatingly unfunny and pitifully unromantic ',\n",
       " 'enriched by an imaginatively mixed cast of antic spirits ',\n",
       " \"which half of dragonfly is worse : the part where nothing 's happening , or the part where something 's happening \",\n",
       " 'in world cinema ',\n",
       " 'very good viewing alternative ',\n",
       " 'the plot is nothing but boilerplate clichés from start to finish , ',\n",
       " 'the action is stilted ',\n",
       " 'on all cylinders ',\n",
       " 'will find little of interest in this film , which is often preachy and poorly acted ',\n",
       " 'by far the worst movie of the year ',\n",
       " 'sit through , ',\n",
       " \"more than another `` best man '' clone by weaving a theme throughout this funny film \",\n",
       " \"it 's about issues most adults have to face in marriage and i think that 's what i liked about it -- the real issues tucked between the silly and crude storyline \",\n",
       " 'heroes ',\n",
       " 'oblivious to the existence of this film ',\n",
       " 'sharply ',\n",
       " 'the entire point of a shaggy dog story , of course , is that it goes nowhere , and this is classic nowheresville in every sense . ',\n",
       " 'sometimes dry ',\n",
       " \"as they come , already having been recycled more times than i 'd care to count \",\n",
       " 'covers this territory with wit and originality , suggesting that with his fourth feature ',\n",
       " 'a $ 40 million version of a game ',\n",
       " 'gorgeous and deceptively minimalist ',\n",
       " 'cross swords with the best of them and ',\n",
       " 'as a fringe feminist conspiracy theorist ',\n",
       " \"proves once again he has n't lost his touch , bringing off a superb performance in an admittedly middling film . \",\n",
       " 'disappointments ',\n",
       " 'the horrors ',\n",
       " 'a muddle splashed with bloody beauty as vivid as any scorsese has ever given us . ',\n",
       " 'many pointless ',\n",
       " 'a beautifully ',\n",
       " 'contrived , well-worn situations ',\n",
       " 'a doa ',\n",
       " \"poor ben bratt could n't find stardom if mapquest emailed him point-to-point driving directions . \",\n",
       " \"to be as subtle and touching as the son 's room \",\n",
       " 'starts with a legend ',\n",
       " 'far less sophisticated and ',\n",
       " 'rich veins of funny stuff in this movie ',\n",
       " 'no apparent joy ',\n",
       " 'shot on ugly digital video ',\n",
       " \"... a sour little movie at its core ; an exploration of the emptiness that underlay the relentless gaiety of the 1920 's ... the film 's ending has a `` what was it all for ? '' \",\n",
       " 'though ford and neeson capably hold our interest , but its just not a thrilling movie ',\n",
       " 'is pretty damned funny . ',\n",
       " 'we never feel anything for these characters ',\n",
       " \"'s a lousy one at that \",\n",
       " 'the corporate circus that is the recording industry in the current climate of mergers and downsizing ',\n",
       " 'the storylines are woven together skilfully , the magnificent swooping aerial shots are breathtaking , and the overall experience is awesome . ',\n",
       " 'of the most highly-praised disappointments i ',\n",
       " 'sounds like a cruel deception carried out by men of marginal intelligence , with reactionary ideas about women and a total lack of empathy . ',\n",
       " 'seem fresh ',\n",
       " 'to the dustbin of history ',\n",
       " 'as a director , eastwood is off his game ',\n",
       " 'pays earnest homage to turntablists ',\n",
       " 'weak and ',\n",
       " 'skip this dreck , ',\n",
       " 'contains very few laughs and even less surprises ',\n",
       " \"film to affirm love 's power to help people endure almost unimaginable horror \",\n",
       " 'are an absolute joy ',\n",
       " 'generates ',\n",
       " \", like life , is n't much fun without the highs and lows \",\n",
       " 'based on a true and historically significant story ',\n",
       " 'well-rounded tribute ',\n",
       " \", though many of the actors throw off a spark or two when they first appear , they ca n't generate enough heat in this cold vacuum of a comedy to start a reaction . \",\n",
       " 'so much like a young robert deniro ',\n",
       " 'khouri manages , with terrific flair , to keep the extremes of screwball farce and blood-curdling family intensity on one continuum . ',\n",
       " 'fashioning an engrossing entertainment out ',\n",
       " 'spiffy animated feature ',\n",
       " \"that 's so sloppily written and cast that you can not believe anyone more central to the creation of bugsy than the caterer \",\n",
       " 'alternating between facetious comic parody and pulp melodrama , this smart-aleck movie ... tosses around some intriguing questions about the difference between human and android life ',\n",
       " 'strung-together moments ',\n",
       " ', generous and subversive artworks ',\n",
       " \"it does n't follow the stale , standard , connect-the-dots storyline which has become commonplace in movies that explore the seamy underbelly of the criminal world \",\n",
       " 'funny yet ',\n",
       " 'overbearing and over-the-top ',\n",
       " \"it 's robert duvall ! \",\n",
       " 'rich and sudden wisdom ',\n",
       " \"acted and directed , it 's clear that washington most certainly has a new career ahead of him \"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample of a review\n",
    "sst2['train']['sentence'][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e08b9a3-4742-4aa5-b2ff-e10ca7553c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contains no wit , only labored gags '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2['train']['sentence'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9eab18-09eb-4f34-960f-8da15472c064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uneasy mishmash of styles and genres .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2['test']['sentence'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be7f73b-c3e6-474d-bb82-f52244fd3501",
   "metadata": {},
   "source": [
    "## INSTRUCTOR 👨‍🏫👩‍🏫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8733338-6e89-4e25-bd1a-70842cb6063d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "#dir(INSTRUCTOR)\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5222b5fc-46ff-4f1a-9f83-74ec0b5f3ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.3520196e-02 -1.4751182e-02 -2.1812499e-02 ... -5.3077709e-02\n",
      "  -1.9894231e-02  4.6290603e-02]\n",
      " [-4.0275887e-02  9.5391721e-03 -2.0763531e-02 ... -5.9346016e-02\n",
      "   1.6357798e-02  3.0490218e-02]\n",
      " [-3.5560861e-02 -2.3208736e-03 -1.3518459e-02 ... -2.9144358e-02\n",
      "   2.5669584e-02  6.4498499e-02]\n",
      " ...\n",
      " [-2.8902860e-02  9.5078964e-03 -1.9643229e-02 ... -3.4858063e-02\n",
      "   3.1831473e-02  4.5890577e-02]\n",
      " [-3.0532386e-02 -3.9113317e-02 -1.6344437e-02 ... -3.8398307e-02\n",
      "   2.1053439e-03  3.6098324e-02]\n",
      " [-3.3510122e-02 -2.5493458e-03 -1.9426448e-02 ... -6.0843486e-02\n",
      "   8.7424909e-05  4.9884342e-02]]\n"
     ]
    }
   ],
   "source": [
    "#dir(model)\n",
    "#get the embedding\n",
    "sentence = sst2['train']['sentence'][0:10]\n",
    "#instruction = \"semantic\"\n",
    "embeddings = model.encode(sentence)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcac4c-296f-4d1f-9f12-fe01ba5d9ac6",
   "metadata": {},
   "source": [
    "## Calculate Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46b2ca0b-2b6d-480c-8a27-5a84bd6fda81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.791337   0.7545798  0.792951   0.76039135 0.7968184  0.76513994\n",
      "  0.77183414 0.7897898  0.7880728  0.77604973]\n",
      " [0.8359742  0.79563093 0.83904195 0.8281418  0.85586786 0.7920675\n",
      "  0.81078637 0.83478475 0.8178705  0.8116954 ]\n",
      " [0.8400682  0.81742257 0.80808955 0.7690075  0.83724487 0.821731\n",
      "  0.81950223 0.84481335 0.80259347 0.83987105]\n",
      " [0.8199604  0.7720649  0.85261905 0.74618435 0.7806753  0.7816093\n",
      "  0.7777296  0.83189476 0.79248047 0.8085593 ]\n",
      " [0.8210979  0.8378202  0.7874433  0.84053195 0.8511729  0.762864\n",
      "  0.82096875 0.7945789  0.79173076 0.79623735]\n",
      " [0.82384497 0.7801317  0.8040639  0.79008037 0.8473133  0.78129834\n",
      "  0.7880322  0.7888309  0.78303826 0.82346255]\n",
      " [0.8051164  0.8481436  0.79881895 0.7911173  0.81736356 0.7747912\n",
      "  0.8397882  0.82004267 0.76506215 0.81981665]\n",
      " [0.8505894  0.8004862  0.8175191  0.7937734  0.83820117 0.8168696\n",
      "  0.81293756 0.85264456 0.8296662  0.8161603 ]\n",
      " [0.8235054  0.7667987  0.79704994 0.77834255 0.8182266  0.78134567\n",
      "  0.78994125 0.8060272  0.78559744 0.8066112 ]\n",
      " [0.81426024 0.8517576  0.7928171  0.788291   0.8171367  0.7804682\n",
      "  0.8303825  0.8412075  0.7848222  0.8164028 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sentences_a = sst2['train']['sentence'][0:10]\n",
    "#print(sentences_a)\n",
    "sentences_b = sst2['train']['sentence'][10:20]\n",
    "embeddings_a = model.encode(sentences_a)\n",
    "embeddings_b = model.encode(sentences_b)\n",
    "similarities = cosine_similarity(embeddings_a,embeddings_b)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c778718-5a6a-44de-a02b-429bb9b8bb6e",
   "metadata": {},
   "source": [
    "## modified code to take care of the feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5f8ff4b-c1a7-4d96-9656-67e86a6c64a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')\n",
    "sentences_a = sst2['train']['sentence'][0:10]\n",
    "sentences_b = sst2['train']['sentence'][10:20]\n",
    "\n",
    "def extract_ngrams(sentence, n):\n",
    "    tokens = sentence.split()\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "    return [' '.join(gram) for gram in ngrams_list]\n",
    "\n",
    "similarities = []\n",
    "\n",
    "for sentence_a in sentences_a:\n",
    "    for sentence_b in sentences_b:\n",
    "        embeddings_a = model.encode(sentence_a)\n",
    "        embeddings_b = model.encode(sentence_b)\n",
    "        similarity = cosine_similarity(embeddings_a.reshape(1, -1), embeddings_b.reshape(1, -1))[0][0]\n",
    "        \n",
    "        # Perform n-gram averaging\n",
    "        n = 2  # You can adjust the n-gram size\n",
    "        ngrams_a = extract_ngrams(sentence_a, n)\n",
    "        ngrams_b = extract_ngrams(sentence_b, n)\n",
    "        \n",
    "        # Calculate the importance of common n-grams\n",
    "        common_ngrams = set(ngrams_a) & set(ngrams_b)\n",
    "        ngram_importance = {ngram: ngrams_a.count(ngram) + ngrams_b.count(ngram) for ngram in common_ngrams}\n",
    "        \n",
    "        similarities.append((similarity, ngram_importance))\n",
    "\n",
    "# Now you have a list of tuples containing similarity scores and n-gram importance dictionaries for each pair of sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42b0abab-0464-4b53-b71a-fa33ba5db08a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# generate ngrams up to trigrams\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     d \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, text_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([text0, text1]):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # generate ngrams up to trigrams\n",
    "    d = defaultdict(list)\n",
    "    for i, text_i in enumerate([text0, text1]):\n",
    "        texts = imodelsx.util.generate_ngrams_list(text_i, ngrams=3, all_ngrams=True)\n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        outputs = model(**inputs).last_hidden_state.detach().cpu().numpy()\n",
    "        embs = np.mean(outputs, axis=1).squeeze()\n",
    "        embs_mean = np.mean(embs, axis=0)\n",
    "\n",
    "        d['texts'].append(texts)\n",
    "        d['embs'].append(embs)\n",
    "        d['embs_mean'].append(embs_mean)\n",
    "\n",
    "    # calculate feature importance for similarity\n",
    "    denominator = calculate_denominator(d['embs_mean'][0], d['embs_mean'][1])\n",
    "    d['imps'].append((d['embs'][0] @ d['embs_mean'][1]) / denominator)\n",
    "    d['imps'].append((d['embs'][1] @ d['embs_mean'][0]) / denominator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9223e4a7-6579-48f7-ac72-e1e574bce4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83799434-4120-4ce7-8af5-5a710b923988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAXYEAR',\n",
       " 'MINYEAR',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'date',\n",
       " 'datetime',\n",
       " 'datetime_CAPI',\n",
       " 'sys',\n",
       " 'time',\n",
       " 'timedelta',\n",
       " 'timezone',\n",
       " 'tzinfo']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35481f-fbf4-4f1b-9ca3-3d787a12081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
